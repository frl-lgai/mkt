seed: 42
model_dir: /w/exaone_2022/model_8.8B_BI_MT_02
data_dir: /w/data/mkt
max_length: 1024
num_processes: 1

trainer:
  output_dir: /w/exp/mkt/model_8.8B_BI_MT_02
  num_train_epochs: 10
  
  learning_rate: 0.00002
  lr_scheduler_type: cosine
  warmup_ratio: 0.1
  
  per_device_train_batch_size: 10
  per_device_eval_batch_size: 2
  
  evaluation_strategy: steps
  eval_steps: 10
  
  save_strategy: steps
  save_steps: 50
  
  load_best_model_at_end: true
  
  logging_strategy: steps
  logging_first_step: true
  logging_steps: 10
  
  report_to: wandb  
  deepspeed: ../configs/stage3.json

wandb:
  group: finetune-lingvo
  project: mkt
  entity: frl-lgai