seed: 42
model_name_or_path: skt/kogpt2-base-v2
data_dir: /w/mkt/data/kobaco
max_length: 1024
num_proc: 1
eos_token: <|endoftext|>

trainer:
  output_dir: /w/exp/mkt/skt_kogpt2
  num_train_epochs: 30
  
  learning_rate: 0.0001
  lr_scheduler_type: cosine
  warmup_ratio: 0.1
  
  per_device_train_batch_size: 10
  per_device_eval_batch_size: 2
  
  evaluation_strategy: steps
  eval_steps: 10
  
  save_strategy: steps
  save_steps: 50
  
  load_best_model_at_end: true
  
  logging_strategy: steps
  logging_first_step: true
  logging_steps: 10
  
  report_to: wandb  
  deepspeed: configs/stage3.json

wandb:
  group: finetune-skt-kogpt2
  project: mkt
  entity: frl-lgai